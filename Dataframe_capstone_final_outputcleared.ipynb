{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=\"6\"> Data Conversion and Extraction File</font>  \n",
    "<font size=\"3\"> *By: Tristan Yuen*   \n",
    "*Date: December 15th, 2020* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import starting libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening json file from my computer\n",
    "with open (\"C:\\\\Users\\\\Arkateks\\\\Desktop\\\\BrainStation Files\\\\Capstone\\\\spotify_million_playlist_dataset\\\\data\\\\mpd.slice.2000-2999.json\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's see what the data shows\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can see the entire dataset is nested within a dictionary. Within the overall dictionary, there seems to be a two dictioanries, one that includes just general information about this json file while the other dictionary holds all the playlists within a list. Furthermore, the list in itself containts a dictionary who's keys are various factors about the playlist itself. We can see in the first one in terms of features being: name of playlist, if it is collaborative or not, playlist id, last changed, number of songs, number of different albums, how many followers, and tracks. Now tracks initself is a list of a nested dictionary of all the different songs within the playlist and its own brief metadata. The data includes the position of the track within the playlist, artist name, the track id for spotify, album id for spotify, the name of the song, as well as how long is it and the album name. Each of these tracks is its own dictionary. We can see that there are many layers of data within here like an onion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial test to see how to parse through the data\n",
    "print(data[\"playlists\"][2][\"tracks\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an attempt to iterate through this list to see how I would extract the artist names from the list. We can see here I've managed to reach the playlist level within the dataset. However, the key thing to note is what the two integers represent here. The first integer shows which playlist is it in terms of of position. So in the case above it would be the third playlist of this entire set. The second integer represents the position of the track and here it would the first track of the playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"playlists\"][0][\"tracks\"][0][\"artist_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following through with what I did above, I see that I need to use the `artist_name` key to access the artist name within the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artists names in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a for loop to gather all artist name into a list\n",
    "#setting up an empty list variable\n",
    "artist = []\n",
    "\n",
    "#for loop that goes 3 levels deep from our test above to extract the data needed\n",
    "for playlist in data[\"playlists\"]:\n",
    "    for track in playlist[\"tracks\"]:\n",
    "        artist.append(track[\"artist_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check to see if for loop ran correctly\n",
    "artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the entire list of all the artists that are within this json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how many totol artists are there\n",
    "u_artists = list(set(artist))\n",
    "len(u_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9861 unique artists within this playlist dataset. Below in the commentted out code was the first iteration of the code I used to find the number of unique artists within the list and I shortened it with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_artists = []\n",
    "\n",
    "#for names in artist: \n",
    "    # check if exists in unique_list or not \n",
    "    #if names not in unique_artists: \n",
    "        #unique_artists.append(names) \n",
    "        \n",
    "#len(unique_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much data cleaning to do as this data was given as part of a challenge from spotify, so there is comfort in the fact that they purposed the data to focus more on the results, so we know that the data is clean and there would be no need to search for missing data of any sorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know at this point that we want to use the DictVectorizer is in tandem with the Counter function within collections. Counter allows us to count how many of each artist which is in a string format. Afterwards DictVectorizer takes the strings along with the count that the Counter creates. The artist will become the key and the value will be the count of how many times the artist appears within the playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the for loop to extract the artists names\n",
    "\n",
    "#empty dictionary name to store all the playlists with all the artists names\n",
    "dict = {}\n",
    "\n",
    "#empty list to store the artists names\n",
    "artists_names =[]\n",
    "\n",
    "#iterating through a range of 1000 as each json file has 1000 playlists\n",
    "for i in range(1000):\n",
    "    dict[i] = artists_names \n",
    "    j = len(data[\"playlists\"][i][\"tracks\"])    #this helps us make sure that the first dictionary ends when the first playlist ends so that when we need to iterate through a new playlist it creates a new dictionary\n",
    "    artists_names = []\n",
    "    for n in range(j):\n",
    "        artists_names.append(data[\"playlists\"][i][\"tracks\"][n][\"artist_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See how long the dictionary is in its first position\n",
    "len(dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of tracks in playlist 1\n",
    "data[\"playlists\"][0][\"num_tracks\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above that our for loop ran successfully through a quick check as the length of the playlist match with the data given within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import Counter from the collections library\n",
    "from collections import Counter\n",
    "\n",
    "#setting up empty list to store our values\n",
    "artists_cnt = []\n",
    "\n",
    "#running a for loop to count how many times an artist appears within a playlist\n",
    "for i in range(1000):\n",
    "    artists_title = Counter(dict[i])\n",
    "    artists_cnt.append(artists_title)\n",
    "    \n",
    "artists_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From aboe we can see now that each position within the list is its own playlist. Within each position is the counter variable that has all the counts embedded within a dictionary where the keys are the artists and the values are how many times the artist appears within the playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the first position from the list as it is an empty Counter variable\n",
    "del artists_cnt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing DictVectorizer to help us change the above to a sparse matrix \n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting our DictVecotrizer as a variable\n",
    "v = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting our list into Dictvectorizer\n",
    "v.fit(artists_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the data once the it has been fitted and setting it as a variable\n",
    "surprise_trial = v.transform(artists_cnt)\n",
    "surprise_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Here setting a variable for plotting later on of all the feature names within the sparse matrix which will be all the artists within the list that we created before\n",
    "names = v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract the information and put it in a data frame to make it easier to see what has occured\n",
    "df = pd.DataFrame(columns=v.get_feature_names(), data=artists_cnt)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how the sparse matrix is made out now within a dataframe. Interestingly we see some unique artists names as DictVectorizer seems to have sorted all the artists into alphabetical order starting with all the symbols first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see if the dataframe is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate for a playlist which is a row within the dataframe\n",
    "playlist_997 = df.loc[997, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a quick equation to see if the count of the playlist 997 matches the one within the list we created before\n",
    "Counter(playlist_997[playlist_997.notna()].to_dict()) == artists_cnt[997]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above equation ran true so we move on to show visuals about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all the NaN's in the dataframe above to 0 for numpy calculations\n",
    "df_zeroes = df.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to see which is the top artists from the above sparse matrix, I can't do that as the NaN's stop me from using any numpy calculations. As a result, we have to convert them in order to do some quick visualizations for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Artists chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting a new row on the bottom to tally all the times an artists appears\n",
    "artists_total  = pd.DataFrame(df_zeroes.sum(axis = 0), columns = ['Total'])\n",
    "artists_total.reset_index(level = 0 , inplace = True)\n",
    "artists_total = artists_total.sort_values(by = 'Total', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created a new row on the bottom of the dataframe to calculate how many times an artist appeared within this dataset. We had to do the row as all the columns are the artists leading for the calculation to be done in a vertical sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot top 10 artists in playlist\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.bar(artists_total['index'].head(10), artists_total['Total'].head(10), color = 'forestgreen')\n",
    "plt.xlabel('Artists')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Top 10 Artists in Playlist Set 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above chart, we can see that the top 10 artists within this playlist is mainly hip hop and pop artists. Not surprisingly here, because the Spotify dataset is 1 million playlists that were curated between 2010 and 2017 and all the playlists originate from North America. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list to store values\n",
    "playlist_len = []\n",
    "\n",
    "#for loop to extract the length of each playlist and put its numeric value into a list\n",
    "for i in range(999):\n",
    "    length_playlist = len(artists_cnt[i])\n",
    "    playlist_len.append(length_playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum(playlist_len)/len(playlist_len)\n",
    "print(\"The average is \", round(avg,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average length of a playlist seems to be about ~38 songs. This seems about right as numerous articles I have read in terms of creating the prefect playlist say that the range should be around 30-50 songs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list to store values\n",
    "songs = []\n",
    "\n",
    "#for loop for extracitng the number of songs within this playlist dataset\n",
    "for playlist in data[\"playlists\"]:\n",
    "    for track in playlist[\"tracks\"]:\n",
    "        songs.append(track[\"track_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding how many unique songs are there\n",
    "u_song = list(set(songs))\n",
    "len(u_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 30,230 unique songs within this playlist. This is a good amount of diversity within this dataset and its only 1 of 1000 json files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Song Vectorizer section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the exact same code above. However, this time it instead of drawing out the artists from the dataset and putting them into a sparse matrix with how many times they appear, it is with song titles intead. Ultimately, I did not use any of th section below for my model, but it would be interesting to come back and see how the model would perform with a much larger matrix and a much more specific recommendation. As the bottom section is not used I will not be commenting what each part of the code does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_songs = {}\n",
    "\n",
    "songs_names =[]\n",
    "\n",
    "for i in range(1000):\n",
    "    dict_songs[i] = songs_names\n",
    "    j = len(data[\"playlists\"][i][\"tracks\"])\n",
    "    songs_names = []\n",
    "    for n in range(j):\n",
    "        songs_names.append(data[\"playlists\"][i][\"tracks\"][n][\"track_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_cnt = []\n",
    "\n",
    "for i in range(1000):\n",
    "    songs_title = Counter(dict_songs[i])\n",
    "    songs_cnt.append(songs_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del songs_cnt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.fit(songs_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.transform(songs_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = vs.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract the information and put it in a data frame to make it easier to see what has occured\n",
    "df_songs = pd.DataFrame(columns=vs.get_feature_names(), data=songs_cnt)\n",
    "display(df_songs)# We can extract the information and put it in a data frame to make it easier to see what has occured\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_997_s = df_songs.loc[997, :]\n",
    "Counter(playlist_997_s[playlist_997_s.notna()].to_dict()) == songs_cnt[997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeroes_songs = df_songs.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeroes_songs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_total  = pd.DataFrame(df_zeroes_songs.sum(axis = 0), columns = ['Total'])\n",
    "songs_total.reset_index(level = 0 , inplace = True)\n",
    "songs_total = songs_total.sort_values(by = 'Total', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.bar(songs_total['index'].head(10), songs_total['Total'].head(10), color = 'cornflowerblue')\n",
    "plt.xlabel('Song Title')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('Top 10 Songs in Playlist Set 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "song statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_duration = []\n",
    "\n",
    "for playlist in data[\"playlists\"]:\n",
    "    for track in playlist[\"tracks\"]:\n",
    "        song_duration.append(track[\"duration_ms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = (sum(song_duration)/len(song_duration))/1000/60\n",
    "print(\"The average is song duration is  \", round(avg,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> First iteration of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries from surprise\n",
    "from surprise import Dataset\n",
    "from surprise.reader import Reader\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD as FunkSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store values\n",
    "playlist_num = []\n",
    "artist = []\n",
    "rating = []\n",
    "\n",
    "#iterating through each key within the dictionary and inserting the proper value into its own list\n",
    "for i, counter in enumerate(artists_cnt):\n",
    "    for key, value in counter.items():\n",
    "        playlist_num.append(i)\n",
    "        artist.append(key)\n",
    "        rating.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking lists above and creating its own dictionary and then putting it into a dataframe\n",
    "a_dict = {\"Playlist\":playlist_num, \"Artist\":artist, \"Rating\":rating}\n",
    "df_trial = pd.DataFrame(a_dict)\n",
    "df_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the surprise library for a recommendation system it requires a dataframe to be 3 columns. Either the first or second column has to be the user id while the other is the item id. The third column would be the given rating for that user id combination. As a result, I had to condense my sparse matrix dataframe into 3 lists for values and took those lists and created new keys for each of the lists and created a new dataframe for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks the max rating that will be inputted\n",
    "df_trial['Rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks the minimum rating that will be inputted\n",
    "df_trial['Rating'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the functions built into surprise to load in my dataframe\n",
    "my_dataset = Dataset.load_from_df(df_trial, Reader(rating_scale=(1, 135)))\n",
    "my_train_dataset = my_dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Running a quick model of SVD to see if the model will run\n",
    "my_algorithm = FunkSVD(n_factors=10, \n",
    "                       n_epochs=100, \n",
    "                       lr_all=0.00001,    # Learning rate for each epoch\n",
    "                       biased=False,  # This forces the algorithm to store all latent information in the matrices\n",
    "                       verbose=1)\n",
    "\n",
    "my_algorithm.fit(my_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing new libaries to evaluate the model that was run\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# The surprise package doesn't allow you to test on the trainset we built\n",
    "my_train_dataset, my_test_dataset = train_test_split(my_dataset, test_size=0.5)\n",
    "\n",
    "#setting a predictions variable and running a test to see the results\n",
    "predictions = my_algorithm.test(my_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#seeing what the predictions look like\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "RMSE = accuracy.rmse(predictions, verbose=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "MAE = accuracy.mae(predictions, verbose=False)\n",
    "print(MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCP = accuracy.fcp(predictions, verbose=0)\n",
    "print(FCP) # ideal is 1.0, worst is 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Initial Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import grid search function from surprise\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "#establish parameters grid\n",
    "param_grid = {'n_epochs': [50, 100, 150, 200, 250], \n",
    "              'lr_all': [0.001, 0.0001, 0.000001],\n",
    "              'reg_all': [0.1, 0.2, 0.3, 0.4]}\n",
    "\n",
    "#run grid search with cross validation of 5 folds\n",
    "gs_trial = GridSearchCV(FunkSVD, param_grid, measures=['rmse', 'mae'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the grid search with my dataframe\n",
    "%%time\n",
    "gs_trial.fit(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_trial.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best RMSE score\n",
    "print(gs_trial.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can a gridsearch and received the best parameters. However, other than the numer of epochs which stood at 150 which was in the middle of my range, the learning rate best parameter was on the edge at 0.001 and the regularization at 0.3. As a result, we don't know for sure if those are the best parameters as both cases seem to be edge cases. As a result, to get the best parameters we will have to do a secondary grid search where we fine tune it even more by putting in more specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataframe for reference\n",
    "df_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the minimum value of the entire rating system\n",
    "df_trial['Rating'].min(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the above code as well with .max() function. and the result was 135. The minimum rating for the dataset is 1 and the max rating is 135."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing out an initial equation of min max scaler\n",
    "((135 - 1) / (df_trial['Rating'].max(axis = 0 ) - 0)) * 9 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the min max scaler function within a for loop so that it can iterate through my dataframe\n",
    "%%time \n",
    "\n",
    "min = 1\n",
    "max = 10 \n",
    "num_rows = len(df_trial['Rating'])\n",
    "scaled_scores = []\n",
    "\n",
    "#iterating through the dataframe\n",
    "for i in range(1000):\n",
    "    if df_trial['Playlist'][i] == [i]:\n",
    "        for i in range(num_rows):\n",
    "            std_playlist = (df_trial['Rating'][i]- min) / (df_trial['Rating'].max(axis = 0) - min) #taking the min max scaler function mathematical equation and inputting into the for loop for iteration\n",
    "            scaled_rating = round(std_playlist * (max - min) + min) #second part of the min max scaler function \n",
    "            scaled_scores.append(scaled_rating)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing new min and max ratings\n",
    "df_trial['Scaled_Ratings'] = scaled_scores\n",
    "print(df_trial['Scaled_Ratings'].max())\n",
    "print(df_trial['Scaled_Ratings'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the unnecessary rating column as surprise library only takes in 3 columns \n",
    "df_scaled = df_trial.drop(['Rating'], axis = 1)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the above section, I realized that surprise may not fun not function as well due to the fact that my rating system is extremely broad. The minimum value is 1 and the maximum value is 135. As a result, surprise may have difficulty finding an accurate function. As a result, I created a for loop so that the ratings would scale based on each playlist. The min max scaler function would be applied on a playlist level which is why I could not just use the library function as it would have scaled it based on the entire dataframe instead of scaling per playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the algorithms within the surprise library \n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD as FunkSVD\n",
    "from surprise.prediction_algorithms.random_pred import NormalPredictor \n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n",
    "from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "from surprise.prediction_algorithms.slope_one import SlopeOne\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVDpp\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading new Dataframe\n",
    "data = Dataset.load_from_df(df_scaled, Reader(rating_scale=(1, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [FunkSVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['rmse'], cv=5, verbose=True)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "\n",
    "#make dataframe for all my tests scores\n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran all of the models and tested them based on residual mean scores to see which model would be the best. From the above dataframe you can see that Baseline Only was the best performing one in terms of residual mean scores while Normal Predictor was the worst. Interestingly, between BaselineOnly and SVD there is not a significant difference between the residual mean scores. The difference is really only 0.1. As a result, when I was deciding on which model to use I landed with SVD. There are two factors. The first factor being that for SVD I am able to explore the latent variables that come with running an SVD variable. The second reason is that SVD within surprise utilizes stochastic gradient descent. The benefits of using SGD is that it is known to be able to converge comparatively more than other methodologies. As a result, when I scale the data up using AWS, using this model will hopefully provide better results. Also comparatively, within the test times, I chose SVD over KNN as computationally it is much less intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reoptimize gridsearch after initial grid search\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_epochs': [60, 70, 80, 90, 100, 110, 120], \n",
    "              'lr_all': [0.1, 0.01, 0.001, 0.0001],\n",
    "              'reg_all': [0, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4]}\n",
    "gs_trial = GridSearchCV(FunkSVD, param_grid, measures=['rmse', 'mae'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs_trial.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs_trial.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second time we run the grid search and this time we see better results wih the best paramter not being near the edge. Moving forward we will continue to use these paramaeters for our FunkSVD algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference dataframe once again\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing approximately how many times Drake appears within a playlist\n",
    "print(df_scaled.loc[df_scaled['Artist'] == 'Drake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checked a random Playlist to see the ratings overall\n",
    "print(df_scaled.loc[df_scaled['Playlist'] == 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading new Dataframe\n",
    "data = Dataset.load_from_df(df_scaled, Reader(rating_scale=(1, 10)))\n",
    "train_data = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#running model after the hyperparamater optimization\n",
    "my_algorithm = FunkSVD(n_factors=10, \n",
    "                       n_epochs=110, \n",
    "                       lr_all=0.001, # Learning rate for each epoch\n",
    "                       reg_all = 0.25,\n",
    "                       biased=False,  # This forces the algorithm to store all latent information in the matrices\n",
    "                       verbose=1)\n",
    "\n",
    "my_algorithm.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the predict function to see the estimated scores \n",
    "my_algorithm.predict(uid = 50, iid = 'Rihanna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afte running the model with the scaled ratings as well as the tuned hyperparameters we use the predict function to see what would a user within the given training dataset rate an artist of our choice. As a result, I ran through multiple iterations and found that most of the estimates were rated 1. As a result, I found this extremely peculiar and checked with the above the ratings and found that most of the ratings within all of the playlist were 1. This tells me that most people only puts an artist within their playlist only once. It seems to me that I will need to change up how the rating system works or else all my top 10 predictions will be random in a sense since everything is rated 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variable to house the user latent variables\n",
    "U = my_algorithm.pu\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variable to house the item latent variables \n",
    "M = my_algorithm.qi.T\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating for the first user profile \n",
    "inner_user_id = train_data.to_inner_uid(1) # find the inner representation of user 1\n",
    "user_profile = U[inner_user_id]\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the latent of a user variables in a plot\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.barh([f'Latent Var{i}' for i in range(1,len(first_song)+1)], user_profile)\n",
    "plt.title(\"Latent Variable Profile of User #1\")\n",
    "plt.ylabel(\"Latent Variable\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the latent of item variables in a plot\n",
    "inner_songs_id = train_data.to_inner_iid('Drake') # find the inner representation of item 1\n",
    "song_profile = M[:, inner_songs_id]\n",
    "song_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting out the item variables\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.barh([f'Latent Var{i}' for i in range(1,len(first_song)+1)], song_profile)\n",
    "plt.title(\"Latent Variable Profile of User #1\")\n",
    "plt.ylabel(\"Latent Variable\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiplying the user and item arrays to see the expected ratings\n",
    "expected_rating = np.dot(user_profile, song_profile)\n",
    "expected_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to check the latent variables to see if anything stood out. However, due to the nature of my dataframe, it would be extremely hard to check the latent variables visually. Possibly as next steps, I could create a function to parse the necessary information so I could look deeper into it. However, for this prototype we will not be investigating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting out distribution of scaled ratings\n",
    "plt.figure()\n",
    "plt.bar(df_scaled['Scaled_Ratings'].value_counts().index,df_scaled['Scaled_Ratings'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled ratings distribution in numeric form\n",
    "df_scaled['Scaled_Ratings'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking further into this scaling problem, I plotted out the distribution of the scaling and not to mmy surpise 99% of the ratings is 1 out of 10. Found out the exact numbers numerically, and it is not a suprise (pun intended) that my prediction function was predicting an estimate of 1 consistently considering 99% of the artists were rated 1 out of 10 by the users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution f ratings prior to standard scaler\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.title(' Distribution of Ratings within the Playlist', fontsize = 25)\n",
    "plt.xlabel('Ratings', fontsize = 20)\n",
    "plt.ylabel('Count of Ratings', fontsize = 20)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.bar(df_trial['Rating'].value_counts().index,df_trial['Rating'].value_counts(), color = 'cornflowerblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking deeper into the scaling issue, the standard scaler formula keeps the variance the same no matter the range. As a result, if post-scaling my distribution is skewed, theoretically pre-scaling my distribution should be just as skewed. As a result, I plotted it to see my distribution before the scaling and not surprisngly we can see that the distribution is extremely skewed towardsthe rating of 1. Consequently, I will have to fix this issue for my final model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
